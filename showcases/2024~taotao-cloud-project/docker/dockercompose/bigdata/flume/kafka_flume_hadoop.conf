#source的名字
agent.sources = kafkaSource
# channels的名字，建议按照type来命名
agent.channels = memoryChannel
# sink的名字，建议按照目标来命名
agent.sinks = hdfsSink
 
# 指定source使用的channel名字
agent.sources.kafkaSource.channels = memoryChannel
# 指定sink需要使用的channel的名字,注意这里是channel
agent.sinks.hdfsSink.channel = memoryChannel
 
#-------- kafkaSource相关配置-----------------
# 定义消息源类型
agent.sources.kafkaSource.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.kafkaSource.kafka.bootstrap.servers = bigdata-standalone-kafka:9092
# 配置消费的kafka topic
agent.sources.kafkaSource.kafka.topics = action_data_log,sys_access_log
# 配置消费者组的id，不能跟spark streaming中group id一样
agent.sources.kafkaSource.kafka.consumer.group.id = kafka2hdfs
# 消费超时时间,参照如下写法可以配置其他所有kafka的consumer选项。注意格式从kafka.xxx开始是consumer的配置属性
agent.sources.kafkaSource.kafka.consumer.timeout.ms = 100
agent.sources.kafkaSource.batchSize = 10
agent.sources.kafkaSource.batchDurationMillis = 1000
agent.sources.KafkaSource.backoffSleepIncrement = 1000
agent.sources.kafkaSource.maxBackoffSleep = 5000
 
#------- memoryChannel相关配置-------------------------
# channel类型
agent.channels.memoryChannel.type = memory
# channel存储的事件容量
agent.channels.memoryChannel.capacity=10
# 事务容量
agent.channels.memoryChannel.transactionCapacity=10
 
#---------hdfsSink 相关配置------------------
agent.sinks.hdfsSink.type = hdfs

agent.sinks.hdfsSink.hdfs.path = hdfs://bigdata-standalone-hadoop-master:9000/user/hive/warehouse/access/%{ctime}

#文件前缀
agent.sinks.hdfsSink.hdfs.filePrefix = access-%{ctime}

#如果文件正在占用，后缀为.tmp.gz
agent.sinks.hdfsSink.hdfs.inUseSuffix = .tmp.gz
#正常文件后缀.log.gz
agent.sinks.hdfsSink.hdfs.fileSuffix = .log.gz
#以下为相关配置 134217728
agent.sinks.hdfsSink.hdfs.useLocalTimeStamp = true
agent.sinks.hdfsSink.hdfs.rollInterval = 0
agent.sinks.hdfsSink.hdfs.rollSize = 1024
agent.sinks.hdfsSink.hdfs.rollCount = 0
agent.sinks.hdfsSink.hdfs.batchSize = 10
agent.sinks.hdfsSink.hdfs.fileType = CompressedStream
agent.sinks.hdfsSink.hdfs.codeC = gzip
agent.sinks.hdfsSink.hdfs.idleTimeout = 300
agent.sinks.hdfsSink.hdfs.threadsPoolSize = 10
agent.sinks.hdfsSink.hdfs.callTimeout = 60000
 
#自定义拦截
agent.sources.kafkaSource.interceptors = i1
agent.sources.kafkaSource.interceptors.i1.type = com.taotao.cloud.flume.interceptor.AccessLogSourceInterceptor$Builder
