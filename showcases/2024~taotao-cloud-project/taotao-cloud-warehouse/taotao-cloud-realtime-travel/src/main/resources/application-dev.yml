server:
  port: 33334
  http2:
    enabled: true
  undertow:
    buffer-size: 2048
    direct-buffers: true
    threads:
      io: 16
      worker: 256
    accesslog:
      dir: ${user.home}/logs/undertow
      enabled: true
  servlet:
    application-display-name: ${spring.application.name}

jasypt:
  encryptor:
    password: ${TAOTAO_CLOUD_ENCRYPTOR_PASSWORD:taotao-cloud}
    algorithm: PBEWITHHMACSHA512ANDAES_256
    property:
      prefix: "ENC@["
      suffix: "]"

redisson:
  password: ${TAOTAO_CLOUD_REDIS_PASSWORD:taotao-cloud}
  single-server-config:
    address: ${TAOTAO_CLOUD_REDIS_HOST:192.168.10.200}:${TAOTAO_CLOUD_REDIS_PORT:6379}

arthas:
  # telnetPort、httpPort为 -1 ，则不listen telnet端口，为 0 ，则随机telnet端口
  # 如果是防止一个机器上启动多个 arthas端口冲突。可以配置为随机端口，或者配置为 -1，并且通过tunnel server来使用arthas。
  # ~/logs/arthas/arthas.log (用户目录下面)里可以找到具体端口日志
  telnetPort: -1
  httpPort: -1
  # 127.0.0.1只能本地访问，0.0.0.0则可网络访问，但是存在安全问题
  ip: 0.0.0.0
  agent-id: ${spring.application.name}
  app-name: ${spring.application.name}
  tunnel-server: ws://192.168.10.200:7777/ws

spring:
  cloud:
    compatibility-verifier:
      enabled: false
  lifecycle:
    timeout-per-shutdown-phase: 30s
  main:
    allow-bean-definition-overriding: true
    banner-mode: off
  application:
    name: taotao-cloud-open
  sleuth:
    enabled: true
    web:
      client:
        enabled: true
    sampler:
      probability: 1.0
  zipkin:
    enabled: true
    base-url: http://${TAOTAO_CLOUD_ZIPKIN_HOST:192.168.10.200}:${TAOTAO_CLOUD_ZIPKIN_PORT:9411}
    discoveryClientEnabled: false
    sender:
      type: WEB
  redis:
    #host: ${TAOTAO_CLOUD_REDIS_HOST:192.168.10.200}
    #port: ${TAOTAO_CLOUD_REDIS_PORT:6379}
    #database: 1
    #password: ${TAOTAO_CLOUD_REDIS_PASSWORD:taotao-cloud}
    connect-timeout: 60000
    cluster:
      nodes: 192.168.10.200:7100,192.168.10.200:7101,192.168.10.200:7102,192.168.10.200:7103,192.168.10.200:7104,192.168.10.200:7105
      max-redirects: 3
    #sentinel:
    #  master:
    #  nodes:
    client-type: lettuce
    lettuce:
      pool:
        max-active: 1500
        max-wait: 5000
        max-idle: 500
        min-idle: 100
    redisson:
      config: |
        clusterServersConfig:
          idleConnectionTimeout: 10000
          connectTimeout: 10000
          timeout: 3000
          retryAttempts: 3
          retryInterval: 1500
          failedSlaveReconnectionInterval: 3000
          failedSlaveCheckInterval: 60000
          password: null
          subscriptionsPerConnection: 5
          clientName: null
          loadBalancer: !<org.redisson.connection.balancer.RoundRobinLoadBalancer> {}
          subscriptionConnectionMinimumIdleSize: 1
          subscriptionConnectionPoolSize: 50
          slaveConnectionMinimumIdleSize: 24
          slaveConnectionPoolSize: 64
          masterConnectionMinimumIdleSize: 24
          masterConnectionPoolSize: 64
          readMode: "SLAVE"
          subscriptionMode: "SLAVE"
          nodeAddresses:
          - "redis://192.168.10.200:7100"
          - "redis://192.168.10.200:7101"
          - "redis://192.168.10.200:7102"
          - "redis://192.168.10.200:7103"
          - "redis://192.168.10.200:7104"
          - "redis://192.168.10.200:7105"
          scanInterval: 1000
          pingConnectionInterval: 0
          keepAlive: false
          tcpNoDelay: false
        threads: 16
        nettyThreads: 32
        codec: !<org.redisson.codec.MarshallingCodec> {}
        transportMode: "NIO"
  kafka:
    bootstrap-servers: ${TAOTAO_CLOUD_KAFKA_HOST:192.168.10.200}:${TAOTAO_CLOUD_KAFKA_PORT:9092}
    producer:
      retries: 1
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: 0
      properties:
        linger.ms: 100
    consumer:
      auto-commit-interval: 1S
      auto-offset-reset: earliest
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      concurrency: 5
      ack-mode: manual_immediate
      missing-topics-fatal: false

taotao:
  cloud:
    prometheus:
      enabled: true
    dinger:
      enabled: true
      httpclient:
        enabled: true
      threadpool:
        enabled: true
      project-id: ${spring.application.name}
      dingers:
        dingtalk:
          tokenId: ${DINGDING_TOKEN_ID:2f81a18fd235ffbecc00519d53bb8054a7ff3e50f3287e3e4c5fef6e5c8e1016}
          secret: ${DINGDING_SECRET:SEC2ec149b6eaab26a16b3d6c78845848251d0667fb8aa288b0e79d8675e4608d80}
    core:
      enabled: true
      env: dev

management:
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    metrics:
      enabled: true
    prometheus:
      enabled: true
    shutdown:
      enabled: true
    health:
      probes:
        enabled: true
    env:
      post:
        enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
  health:
    elasticsearch:
      enabled: false

logging:
  level:
    root: INFO
    org.springframework.web: off
    org.springframework.security: off
    org.springframework.security.oauth2: off
    org.springframework.boot.autoconfigure: off
